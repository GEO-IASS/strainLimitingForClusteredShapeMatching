%%% template.tex
%%%
%%% This LaTeX source document can be used as the basis for your technical
%%% paper or abstract.

%%% The parameter to the ``documentclass'' command is very important.
%%% - use ``review'' for content submitted for review.
%%% - use ``preprint'' for accepted content you are making available.
%%% - use ``tog'' for technical papers accepted to the TOG journal and
%%%   for presentation at the SIGGRAPH or SIGGRAPH Asia conference.
%%% - use ``conference'' for final content accepted to a sponsored event
%%%   (hint: If you don't know, you should use ``conference.'')

\documentclass[review]{acmsiggraph}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{wasysym}
\usepackage[scaled=.92]{helvet}
\usepackage{times}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{url}
\usepackage[labelfont=bf,textfont=it]{caption}
\usepackage{color}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{enumitem}
\usepackage{authblk}

\input{adamscommands}
%%% Make the ``BibTeX'' word pretty...

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

%%% Used by the ``review'' variation; the online ID will be printed on 
%%% every page of the content.

\TOGonlineid{70}

%%% Used by the ``preprint'' variation.

\TOGvolume{0}
\TOGnumber{0}

\title{Clustering and Collision Detection for Clustered Shape Matching}
\author[*]{Ben Jones}
\author[**]{Joshua A. Levine}
\author[***]{Tamar Shinar}
\author[*]{Adam W. Bargteil}
\affil[*]{University of Utah}
\affil[**]{Clemson University}
\affil[***]{University of California, Riverside}
\pdfauthor{}

\keywords{Shape Matching, Ductile Fracture}

\begin{document}

%%% This is the ``teaser'' command, which puts an figure, centered, below 
%%% the title and author information, and above the body of the content.

% \teaser{
%   \includegraphics[width=\linewidth]{Figures/teaser}
%   \caption{Left: An armadillo is tortured by being torn apart by the arms while being fired upon by spherical projectiles.  Center: A heartbreaking example.  Right: Tearing a slice of swiss cheese.}
%   \label{fig:teaser}
% }

\maketitle

\begin{abstract}
In this paper, we address clustering and collision detection in the clustered shape matching simulation framework
for deformable bodies.  Our clustering algorithm resembles fuzzy c-means and gives particles weighted membership in clusters.
We then use the weights to divide the particles mass among the clusters, resulting in very even distribution of mass over an 
object.  By design our clustering algorithm also forms spherical clusters yielding exceptionally convenient collision geometry.  We further 
enhance this simple collision proxy with halfspaces to allow for fracture or other simple geometric operations.
The resulting approach is fast, versatile, and simple to implement.
\end{abstract}

\begin{CRcatlist}
  \CRcat{I.3.7}{Computer Graphics}{Three-Dimensional Graphics and Realism}{Animation};
  \CRcat{I.6.8}{Simulation and Modeling}{Types of Simulation}{Animation}.
\end{CRcatlist}

\keywordlist

%% Required for all content. 

\copyrightspace

\section{Introduction}\label{sec:Introduction}
{\em Shape matching} is a geometrically motivated technique for animating deformable bodies introduced
a decade ago by \Mueller and colleagues~\shortcite{Mueller:2005:MDB}.
\fref{fig:shapematching} summarizes the approach.


\begin{figure*}
\includegraphics[width=\linewidth]{Figures/shapematching.png}
\caption{Shape Matching Overview: (a) An object (here, a square) is sampled with particles, $p_i$, to get rest positions, $\B{r}_i$.  
(b) As particles are subjected to external forces and constraints, their positions, $\B{x}_i$, are updated in world space.  
(c)  The best-fitting rigid transformation of the particles' rest positions, $\B{r}_i$, 
to their world positions, $\B{x}_i$ is computed.  The dotted red circles are the {\em goal} positions, $\B{g}_i$.  
(d) Hookean springs pull the world positions toward the goal positions.}
\label{fig:shapematching}
\end{figure*}

\section{Related Work}
The geometrically motivated shape matching approach was introduced by \Mueller and 
colleagues~\shortcite{Mueller:2005:MDB}, who demonstrated impressive results and 
described the key advantages of the approach: efficiency, stability, and controllability.
Given these advantages, shape matching is especially appealing in interactive animation contexts such as
video games.  The authors also introduced several extensions including linear and quadratic deformations 
(in addition to rigid deformations), cluster-based deformation, and plasticity.  

Two years later, Rivers and James~\shortcite{Rivers:2007:FFL} introduced lattice-based shape matching,
which used a set of hierarchical lattices to define the shape matching clusters.  They took advantage
of the regular structure of the lattices to achieve extremely high performance.  They also incorporated a 
simple fracture model that removed over-extended links in the lattice.  

Despite impressive results and substantial promise,
the shape matching framework has been largely disregarded by the research community in favor of position-based
dynamics~\cite{Mueller:2007:PBD,Bender:2013:PBM,Bender:2014:ASO,Macklin:2014:UPP}.  One notable exception is
the work of Bargteil and Jones~\shortcite{Bargteil:2014:SLF}, which incorporated strain-limiting into clustered shape matching
and pointed out several advantages of shape matching over position-based dynamics.

\section{Methods}
For completeness and readability, we first briefly review the shape matching approach of \Mueller and colleagues~\shortcite{Mueller:2005:MDB}.
\subsection{Shape Matching}
\label{sec:ShapeMatching}
In the shape matching framework
objects are discretized into a set of particles, $p_i\in\mathcal{P}$, with masses, $m_i$, and rest positions, $\B{r}_i$, 
that follow a path, $\B{x}_i(t)$, in world-space through time.  
Shape matching takes its name from the fact that, each frame, we match the rest shape to 
the deformed shape by finding
the least-squares best-fit rigid transformation from the rest pose
to the current deformed pose by
solving for the rotation matrix, $\B{R}$, and translation
vector, $\B{x}_{cm}-\B{r}_{cm}$, that minimizes
\begin{equation}
\label{eq:sm}
\sum_i m_i \| \B{R}\left(\B{r}_i - \B{r}_{cm}\right)-\left(\B{x}_i-\B{x}_{cm}\right)\|^2.
\end{equation}
The best translation is given by the center-of-mass in the rest and world space.  
Computing the rotation, $\B{R}$, is more involved.  
We first compute the least-squares best-fit linear deformation gradient, $\B{F}$.
Specifically, we seek the $\B{F}$ that minimizes
\begin{equation}
\sum_i m_i \| \B{F}\left(\B{r}_i - \B{r}_{cm}\right)-\left(\B{x}_i-\B{x}_{cm}\right)\|^2.
\end{equation}
Setting the derivative with respect to $\B{F}$ to $0$ and re-arranging terms we arrive at
\begin{equation}
\label{eq:defgrad}
\B{F} = \left(\sum_i m_i \B{O}(\B{x}_i,\B{r}_i)\right)\left(\sum_im_i\B{O}(\B{r}_i,\B{r}_i)\right)^{-1} = \B{A}_{xr}\B{A}_{rr}^{-1},
\end{equation}
where $\B{O}(\cdot,\cdot)$ is the outer product matrix
\begin{equation}
\B{O}(\B{a}_i,\B{b}_i) = \left(\B{a}_i-\B{a}_{cm}\right)\left(\B{b}_{i}-\B{b}_{cm}\right)^T,
\end{equation}
and $\B{A}_{**}$ is a convenient shorthand.
%\begin{align}
%\B{F} = &\left(\sum_i m_i\left(\B{x}_{i}-\B{x}_{cm}\right)\left(\B{r}_{i}-\B{r}_{cm}\right)^T\right)\notag\\
%&\left(\sum_i m_i\left(\B{r}_{i}-\B{r}_{cm}\right)\left(\B{r}_{i}-\B{r}_{cm}\right)^T\right)^{-1},
%\end{align}
%and $m_i$ is the mass of $p_i$. 
We then compute $\B{R}$ using the polar decomposition,
\begin{equation}
\label{eq:decomp}
\B{F} = \B{R}\B{S} = \left(\B{UV}^T\right)\left(\B{V\Sigma V}^T\right)
\end{equation}
where $\B{S}=\B{V\Sigma V}^T$ is a symmetric matrix and $\B{U\Sigma V}^T$ is the singular value decomposition (SVD) of $\B{F}$.
While several researchers (e.g.~\cite{Rivers:2007:FFL}) have pointed out that polar decompositions can be computed faster than the SVD,
especially when warm started, the SVD requires a negligible portion of our computation time and, in our experiments, 
the optimized SVD in the Eigen library was faster than our implementations of polar decompositions.  Furthermore, the SVD is more robust in
the presence of degeneracies or inversions.
We also note that we compute the polar decomposition of $\B{F}$, not
the left matrix ($\B{A}_{xr}$)
%($\sum_im_i\B{O}(\B{x}_i,\B{r}_i)$) 
as done by \Mueller and colleagues~\shortcite{Mueller:2005:MDB}.  This modification
is particularly important if the distribution of mass in the cluster is non-uniform and $\B{F}$ is not a pure rotation.

Given $\B{R}$ and $\B{x}_{cm}-\B{r}_{cm}$, we define goal positions, $\B{g}_i$, as
\begin{equation}
\B{g}_i = \B{R}\left(\B{r}_i-\B{r}_{cm}\right)+\B{x}_{cm}.
\end{equation}
Hookean springs are then used to define forces that move the particles toward the goal positions.

\paragraph{Clustered Shape Matching}
Handling multiple clusters is straightforward.  When computing a particle's contribution to 
cluster quantities, we must divide the particle's mass among its clusters.  To do 
so we introduce a weight $w_{i,c}$ for particle $p_i$ in cluster $c$.  The simplest weighting
scheme divides the particles mass evenly among the $n_i$ clusters it belongs to, $w_{i,c} = 1/n_i$.
%divide the particle's mass by the number of clusters it belongs to,
%essentially replacing $m_i$ with $m_i/n_i$ in equations \eqref{eq:sm}-\eqref{eq:defgrad} 
%and when computing cluster mass and center-of-mass.
In this simple scheme, if particle $p_i$ belongs
to $n_i$ clusters, then the center-of-mass of cluster $c$, $\B{x}_{cm,c}$, is
\begin{equation}
\label{eq:com}
\B{x}_{cm,c} = \frac{\sum_{p_i\in\mathcal{P}_c}(m_iw_{i,c}) \B{x_i}}{\sum_{p_i\in\mathcal{P}_c}(m_iw_{i,c})} = \frac{\sum_{p_i\in\mathcal{P}_c}(m_i/n_i) \B{x_i}}{\sum_{p_i\in\mathcal{P}_c}(m_i/n_i)},
\end{equation}
where $\mathcal{P}_c$ is the set of particles in cluster $c$.
Of course, more general weighting schemes are possible and in our implementation we use the well-known $\mathrm{poly6}(\cdot)$ kernel~\cite{Mueller},
\begin{equation}
\label{eq:poly6}
\mathrm{poly6}(\B{r},h) = \frac{315}{64\pi h^9}\left(h^2-\left|\B{r}\right|^2\right)^3,
\end{equation}
where $h$ is the kernel width and $\B{r}$ is the vector from the cluster center-of-mass to the particle.
Of course, we normalize our weights to a partition of unity,
\begin{equation}
\label{eq:weights}
w_{i,c} = \frac{\mathrm{poly6}(\B{x}_i-\B{x}_{cm,c}, h)}{\sum_{d\in\mathcal{C}}\mathrm{poly6}(\B{x}_i-\B{x}_{cm,d}, h)}
\end{equation}
We do not believe our approach is particularly sentitive
to the choice of kernel, but this kernel has the advantages of finite support, smoothly going to zero at $h$ and being fast to compute.  
We also essentially replace $m_i$ with $w_{i,c}m_i$ in equations \eqref{eq:sm}-\eqref{eq:defgrad} 
For example, when computing the goal position, $\B{g}_i$, for a particle we perform a weighted
average of the goal positions given by each cluster it is a part of.  That is,
\begin{equation}
\B{g}_i = \sum_c w_{i,c}\B{g}_{i,c},
\end{equation}
where $\B{g}_{i,c}$ is the goal position for particle $p_i$ in cluster $c$.

\paragraph{Strain Limiting}
To maintain stability we adopt the strain limiting approach advocated by Bargteil and Jones~\shortcite{Bargteil:2014:SLF}.

\subsection{Clustering}
In our context, there are several desirable properities for a clustering algorithm.  Of utmost importance is that the clusters must overlap, 
otherwise the simulated object will fall apart.  The clusters must include all the particles, preferably with a modest number of clusters.  
Finally, if the clusters are well-approximated by spheres, collision handling becomes far simpler.  While clustering is
very well-studied in machine learning, these properties are unique to our problem and we are not aware of any algorithm tailored to these
constraints.  Consequently, we developed our own approach, which is quite similar to fuzzy c-means, k-means, expecationa maximization (EM), 
and Lloyd's algorithm.  Like all these algorithms, we iteratively perform two-steps:
\begin{enumerate}
\item update cluster membership and weights
\item update cluster centers.
\end{enumerate}
Computing cluster membership involves a standard spherical range query, which is accelareted with a grid data structure.  Computing the weights 
(\eref{eq:weights}) requires evaluating the $\mathrm{poly6}(\cdot)$ (\eref{eq:poly6})
kernel for each particle in each cluster and keeping a running sum of the weights for each particle.  Updating the cluster centers simply requires 
computing~\eref{eq:com} for each cluster using the weights computed in the previous step.  To faciliate satisfying the first requirement that 
all particles belong to at least one particle, we add any particles that are not within $h$ of any cluster center to the nearest cluster 
(in a similar manner to the k-means algorithm).  Any such particles immediately signal that the algorithm has not converged.  Otherwise,
we declare convergence if cluster membership remains the same for two iterations.   If the algorithm
does not converge within a limited number of iterations we increase the number of clusters and/or $h$ until convergence is achieved.


\subsection{Collision Detection}

\section{Results and Discussion}

\begin{table*}
\begin{center}
\caption{Timing results in ms per frame taken on a Macbook Pro with a 2.4Ghz Intel i5 processor.}
\label{table:timing}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
example & \# particles & dynamics & plasticity & fracture & total\\
\hline
armadillo & 20115 & 16  & $<$ 1 & $<$ 1 & 24\\
twisted bar & 5317 & 7 & $<$ 1  & 0 & 7\\
twisted bar with fracture & 5317 & 7  & $<$ 1 & $<$ 1 & 9 \\
projectile & 5325 & 20 & $<$ 1 & $<$ 1 & 29\\
broken heart & 20132 & 22 & $<$ 1 & $<$1 & 31\\
swiss cheese & 25032 & 27 & $<$ 1 & $<$1 & 39 \\
\hline
\end{tabular}
\end{center}
\end{table*}

\paragraph{Limitations and Future Work}

Our blue-noise sampling and k-means clustering improve upon the regular grids and
randomized clusters of Bargteil and Jones~\shortcite{Bargteil:2014:SLF} and are effective for our purposes,
but better approaches certainly exist.  In particular, it would be interesting to explore adaptive sampling
so that computational resources can be focused on interesting areas of the object.  
Changing the sampling over time as done by Pauly and colleagues~\shortcite{Pauly:2005:MAO}
is also a promising avenue for future work, which may help address the geometric limitations discussed above.
It would also be interesting
to consider adaptive and hierarchical clustering techniques; the hierarchical lattices of Rivers and James~\cite{Rivers:2007:FFL}
clearly improved performance and artistic directability.  

The biggest limitation of our approach is a lack of theoretical underpinnings for the clustered shape matching
framework; we do not yet have any mathematical tools to analyze the approach.  We do not really understand
how the method behaves as particle counts or timesteps decrease or as the cluster size or number of clusters change.
This limitation does not mean the approach is not useful.  After all, the finite element method was in use
for decades before a mathematical framework was developed to analyze its properties.  In a similar way,
we believe the clustered shape-matching framework will prove extremely useful in practice while
researchers develop mathematical tools for analysis. 

\paragraph{Conclusion} 
One of the primary advantages of the clustered shape matching approach is that the number of degrees of freedom
is much larger then the number of ``integration units''---clusters in this case.  The opposite is true of finite element
methods with unstructured meshes where the number of tetrahedra is often considerably larger than the number of vertices.  
For graphical applications visual detail, which correlates with the number of degrees of freedom, is of paramount importance
and computation, which correlates with ``integration units,'' is often limited.  
For these reasons, the clustered shape matching framework is extremely appealing for computer animation, 
especially interactive animation.  The utility and versatility of this framework is greatly improved by our extensions 
to clustering and collision handling.




\section*{Acknowledgements}
Removed for anonymous review.

\bibliographystyle{acmsiggraph}
\bibliography{csm}
\end{document}
